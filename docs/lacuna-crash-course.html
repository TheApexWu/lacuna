<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>LACUNA Crash Course</title>
<style>
  * { margin: 0; padding: 0; box-sizing: border-box; }
  body {
    background: #0a0a0a;
    color: #e5e5e5;
    font-family: 'SF Mono', 'Fira Code', 'Consolas', monospace;
    padding: 40px 20px;
    max-width: 720px;
    margin: 0 auto;
    line-height: 1.7;
  }
  h1 { font-size: 28px; letter-spacing: 6px; color: #f59e0b; margin-bottom: 4px; }
  h1 span { color: #525252; font-size: 14px; letter-spacing: 2px; }
  .subtitle { color: #737373; font-size: 12px; letter-spacing: 2px; margin-bottom: 40px; }
  h2 { font-size: 11px; letter-spacing: 3px; color: #737373; margin-top: 36px; margin-bottom: 12px; text-transform: uppercase; }
  h3 { font-size: 14px; color: #f59e0b; margin-bottom: 6px; }
  p { font-size: 13px; color: #a3a3a3; margin-bottom: 10px; }
  .highlight { color: #e5e5e5; font-weight: bold; }
  .amber { color: #f59e0b; }
  .red { color: #ef4444; }
  .green { color: #22c55e; }
  .blue { color: #3b82f6; }
  .oneliner {
    border-left: 2px solid #f59e0b;
    padding: 12px 16px;
    margin: 20px 0;
    background: rgba(245, 158, 11, 0.05);
    font-size: 14px;
    color: #e5e5e5;
  }
  .step { margin-bottom: 16px; padding-left: 16px; border-left: 1px solid #262626; }
  .step-num { font-size: 10px; color: #525252; letter-spacing: 2px; margin-bottom: 2px; }
  .term {
    display: inline-block; background: rgba(245, 158, 11, 0.1);
    border: 1px solid #262626; border-radius: 3px; padding: 1px 6px; font-size: 12px; color: #f59e0b;
  }
  .viz-table { width: 100%; border-collapse: collapse; margin: 10px 0; font-size: 12px; }
  .viz-table td { padding: 6px 10px; border-bottom: 1px solid #1a1a1a; }
  .viz-table td:first-child { color: #737373; width: 120px; }
  .viz-table td:last-child { color: #a3a3a3; }
  .validation {
    background: rgba(34, 197, 94, 0.05); border: 1px solid #1a3a1a;
    border-radius: 6px; padding: 14px; margin: 14px 0; font-size: 12px;
  }
  .validation p { color: #a3a3a3; margin-bottom: 4px; }
  .vocab { display: grid; grid-template-columns: 110px 1fr; gap: 6px 14px; font-size: 12px; margin: 10px 0; }
  .vocab dt { color: #f59e0b; }
  .vocab dd { color: #a3a3a3; }
  hr { border: none; border-top: 1px solid #1a1a1a; margin: 28px 0; }
  .footer { margin-top: 40px; font-size: 10px; color: #525252; letter-spacing: 1px; }
</style>
</head>
<body>

<h1>LACUNA <span>crash course</span></h1>
<div class="subtitle">Team L'ECART -- Mistral Hackathon NYC 2026</div>

<div class="oneliner">
  "Die Grenzen meiner Sprache bedeuten die Grenzen meiner Welt."<br>
  <span style="color:#737373">-- Wittgenstein, Tractatus 5.6</span><br><br>
  The limits of my language mean the limits of my world.
  When two languages read the same text, they read two different worlds.<br><br>
  <span class="amber">Same text, two languages, different concepts activate. LACUNA measures the gap.</span>
</div>

<h2>The Origin</h2>
<p>
  Translation gives you equivalent words, not equivalent understanding.
  The same document processed through the same AI model activates different
  associations depending on the language. No tool existed to show this.
  LACUNA makes the invisible gap visible, measurable, and interactive.
</p>

<h2>The Thesis</h2>
<p>
  Multilingual embedding models do not treat concepts equally across languages.
  Some concepts activate stronger in one language than another. That asymmetry
  reflects how each language encodes history, power, and cultural memory.
  <span class="highlight">LACUNA detects, quantifies, and visualizes those asymmetries.</span>
</p>

<h2>Why It Matters</h2>
<p>
  The Sykes-Picot Agreement processed in English activates mandate, honor, self-determination.
  In Arabic: subjugation, humiliation, resentment. Same text. Same model. Different reading.
  If you deploy AI in 10 languages without checking for this, you are silently collapsing
  distinctions that reshape legal liability, medical risk, and political intent.
</p>

<hr>

<h2>What You Actually See (current build)</h2>

<h3>The Terrain</h3>
<p>
  A 3D landscape built from embedding vectors. 43 concepts from the Treaty of Versailles,
  each defined natively in 10 languages (not translated -- written from scratch in each language).
  The terrain is a 101x101 vertex grid. Each concept contributes a gaussian peak at its position.
</p>
<table class="viz-table">
  <tr><td>Position (x, z)</td><td>UMAP projection of BGE-M3 embedding vectors (1024-dim to 2D). Close concepts = semantically similar in that language.</td></tr>
  <tr><td>Height</td><td>Cosine similarity of concept vector to its cluster centroid, scaled [0.2, 1.0], then exaggerated: sign(h) * |h|^1.3 * 20. Tall = central to its cluster.</td></tr>
  <tr><td>Color</td><td>Cluster assignment. 6 groups. Color only -- has zero effect on probes or measurements.</td></tr>
  <tr><td>Depression</td><td>Lacuna (absent concept). The terrain dips where a concept exists in one language but not another.</td></tr>
  <tr><td>Labels</td><td>Always displayed in English. Float above their terrain peaks.</td></tr>
</table>

<h3>Language Switching (bottom toolbar)</h3>
<p>
  9 language buttons: EN, DE, FR, ES, ZH, JA, AR, KO, RU. Clicking one re-projects the entire terrain
  from that language's embedding vectors. The landscape reshapes over 1.4 seconds (ease-out interpolation
  across all 10,201 vertices). Concepts move because each language's definitions occupy different
  regions of embedding space.
</p>

<h3>The Probe (center of the demo)</h3>
<p>
  Text input bar at top center. Type a sentence or click a pre-loaded probe.
  Hitting PROBE does one thing: embeds your text via <span class="term">mistral-embed</span> (1 API call, 1024-dim),
  then computes cosine similarity against all 43 concept vectors in Language A and Language B.
  That's 86 dot products, under 1 millisecond.
</p>
<p>
  When a probe fires, the terrain shifts to Language B so you see the landscape change.
  Top 10 divergent concepts glow <span class="amber">amber</span>. Everything else dims to 15% opacity.
  A results panel appears on the right with all 43 concepts ranked by divergence.
</p>
<table class="viz-table">
  <tr><td>Divergence</td><td>|cos(query, lang_a_vec) - cos(query, lang_b_vec)|. The gap. Sorted highest first.</td></tr>
  <tr><td>Direction</td><td>Which language pulls harder. <span class="blue">Blue bar</span> = lang_a. <span class="red">Red bar</span> = lang_b. Grey = neutral (&lt;0.005).</td></tr>
  <tr><td>Click a row</td><td>Opens ConceptCard with details. Can trigger the interpreter agent.</td></tr>
</table>

<h3>Pre-loaded Probes (5 historical texts)</h3>
<table class="viz-table">
  <tr><td>Art. 231</td><td>War Guilt Clause, 1919 -- <span class="blue">EN</span> vs <span class="red">DE</span></td></tr>
  <tr><td>Nanking</td><td>Treaty of Nanking, 1842 -- <span class="blue">EN</span> vs <span class="red">ZH</span></td></tr>
  <tr><td>Potsdam</td><td>Potsdam Declaration, 1945 -- <span class="blue">EN</span> vs <span class="red">JA</span></td></tr>
  <tr><td>Sykes-Picot</td><td>Sykes-Picot Agreement, 1916 -- <span class="blue">EN</span> vs <span class="red">AR</span></td></tr>
  <tr><td>38th Parallel</td><td>Korean Partition, 1945 -- <span class="blue">EN</span> vs <span class="red">KO</span></td></tr>
</table>

<h3>Interpreter Agent</h3>
<p>
  Click any concept (on terrain or in results panel) to open its ConceptCard.
  The card shows: cluster, weight per language, lacuna status, 5 nearest neighbors per language.
  Hit "Interpret" to call <span class="term">Mistral Large</span> via the Agents API. The agent receives
  neighbor distances, weight deltas, and lacuna status, then explains why the concept diverges.
</p>

<h3>MORE Menu (bottom toolbar)</h3>
<p>
  Expands to reveal research tools. These are secondary -- not part of the main demo flow.
</p>
<table class="viz-table">
  <tr><td>LACUNAE</td><td>Toggle terrain depressions for absent concepts.</td></tr>
  <tr><td>DIVERGENCE</td><td>Butterfly chart: all 43 concepts, EN weight vs current language weight.</td></tr>
  <tr><td>NETWORK</td><td>2D force-directed graph of concept connections.</td></tr>
  <tr><td>METRICS</td><td>Model-level statistics for the active embedding model.</td></tr>
  <tr><td>AGREEMENT</td><td>43x43 heatmap showing which models agree on concept relationships.</td></tr>
  <tr><td>CONNECT</td><td>Click a concept, see its cross-lingual connection details.</td></tr>
  <tr><td>CLUSTERS</td><td>Edit cluster assignments, colors, create custom clusters.</td></tr>
  <tr><td>Model Selector</td><td>Switch between BGE-M3 (default), curated, e5-large, etc. Terrain recomputes.</td></tr>
</table>

<h3>What Happens Under the Hood</h3>
<table class="viz-table">
  <tr><td>Concept data</td><td>43 concepts, each with: native-language definitions in 10 languages, UMAP positions per language, weights per language, cluster assignment, lacuna flags.</td></tr>
  <tr><td>Terrain build</td><td>For the selected language, read each concept's [x, z] position and weight. Sum gaussian contributions across the grid. Apply nonlinear height exaggeration. Color by cluster.</td></tr>
  <tr><td>Probe flow</td><td>1 mistral-embed call -> cosine similarity vs 43 pre-computed concept vectors in lang_a + 43 in lang_b -> rank by |sim_a - sim_b| -> highlight top 10 on terrain -> show all in results panel.</td></tr>
  <tr><td>Interpret flow</td><td>ConceptCard sends concept metadata to /api/interpret -> creates or reuses Mistral Large agent -> agent returns explanation.</td></tr>
  <tr><td>Transition</td><td>Language switch: snapshot current vertex positions -> compute new target -> interpolate over 1.4s with ease-out. Labels animate in sync.</td></tr>
</table>

<hr>

<h2>Concepts vs Clusters</h2>
<p>
  <span class="highlight">Concepts</span> = the 43 individual ideas (reparations, honor, subjugation, etc.).
  Each is a data point on the terrain with its own position, height, and color.
  Each has a native-language definition in each of 10 languages.
</p>
<p>
  <span class="highlight">Clusters</span> = 6 color groups that organize concepts by theme.
  They determine color only. They have zero effect on probes, divergence scores, or any measurement.
</p>
<table class="viz-table">
  <tr><td><span class="amber">Core</span> (4)</td><td>reparations, armistice, honor, treaty</td></tr>
  <tr><td><span class="blue">Justice</span> (10)</td><td>justice, accountability, punishment, debt, guilt, restitution, sanctions, concession, demilitarization, obligation</td></tr>
  <tr><td><span class="green">Victory</span> (9)</td><td>victory, peace, order, triumph, sovereignty, self-determination, legitimacy, diplomacy, reconstruction</td></tr>
  <tr><td><span class="red">Humiliation</span> (11)</td><td>humiliation, betrayal, injustice, revenge, resentment, subjugation, occupation, propaganda, nationalism, starvation, blockade</td></tr>
  <tr><td><span style="color:#78716c">Lacuna-DE</span> (6)</td><td>dolchstoss, schmach, diktat, kriegsschuld, volkszorn, revanchism</td></tr>
  <tr><td><span style="color:#78716c">Lacuna-EN</span> (3)</td><td>magnanimity, civilizing, mandate</td></tr>
</table>
<p>
  German lacuna concepts (dolchstoss, schmach, diktat, kriegsschuld, volkszorn) are automatically
  filtered out of probe results when German is not one of the two probe languages.
</p>

<hr>

<h2>The Pattern (memorize this)</h2>

<div class="oneliner">
  Same text. Same model. Different conceptual activation. Consistent across 5 texts, 5 language pairs.
</div>

<p>
  <span class="blue">Imperial/colonial language</span> activates: accountability, mandate, honor, legitimacy, magnanimity, justice<br>
  <span class="red">Colonized/occupied language</span> activates: humiliation, subjugation, resentment, restitution, debt, revenge
</p>
<p>
  Strongest example: <span class="highlight">Sykes-Picot</span> (EN vs AR).
  English: accountability, mandate, honor lean blue.
  Arabic: subjugation, humiliation, resentment lean red.
  Colonial language reads protection. Colonized language reads domination.
</p>

<hr>

<h2>For Mistral Judges (API track framing)</h2>

<div class="validation">
  <p><span class="amber">LACUNA runs on Mistral's stack. Two products in one flow:</span></p>
  <p>1. <span class="highlight">mistral-embed</span> -- every live probe. 1 API call per query. The real-time interactive element.</p>
  <p>2. <span class="highlight">Mistral Large via Agents API</span> -- interpreter agent explains WHY concepts diverge. Extractor agent decomposes documents into conceptual frames.</p>
  <p><span style="color:#737373">BGE-M3 built the terrain map. Mistral is the instrument that takes measurements on the map.</span></p>
</div>

<p><span class="amber">Pitch order for judges:</span></p>
<p>
  1. "We built a real-time interactive product on your API that does something nobody else has done."<br>
  2. "mistral-embed detects cross-lingual divergence in real time." (the live demo)<br>
  3. "Mistral Agents API explains the divergence." (the interpretation)<br>
  4. "We validated across 3 independent models -- Mistral's findings hold across architectures." (the defense)
</p>

<hr>

<h2>What we can and cannot claim</h2>

<div class="validation">
  <p><span class="green">CAN:</span> We built an instrument that surfaces cross-lingual divergence in embedding spaces. Patterns are consistent with known cultural asymmetries across 5 language pairs.</p>
  <p><span class="red">CANNOT:</span> That the model "encodes cultural bias." Some divergence may reflect definition variance (different words), not cultural encoding.</p>
  <p><span class="amber">THE LINE:</span> "Whether this reflects cultural encoding or definition semantics is exactly what this instrument helps you test."</p>
</div>

<h2>Judge Q&A (be ready)</h2>

<div class="step">
  <div class="step-num">Q: "Why should I care about 0.06?"</div>
  <p>Don't explain math. Fire Sykes-Picot. Let the split land. "The question isn't whether 0.06 is big. It's that the same text activates different concepts at all."</p>
</div>
<div class="step">
  <div class="step-num">Q: "Isn't this just different definitions?"</div>
  <p>"That's the open research question LACUNA exists to investigate. The patterns are consistent across 5 texts and 5 pairs, aligned with known cultural asymmetries."</p>
</div>
<div class="step">
  <div class="step-num">Q: "Only one model?"</div>
  <p>"Topology validated across 3 models (BGE-M3, e5, LaBSE), all p &lt; 0.002. Live probe uses a 4th (mistral-embed). Four architectures, one finding."</p>
</div>
<div class="step">
  <div class="step-num">Q: "Use case?"</div>
  <p>Bias auditing for multilingual AI. Translation QA. Cross-cultural content analysis. Diplomatic communications.</p>
</div>
<div class="step">
  <div class="step-num">Q: "How is this different from translating?"</div>
  <p>"Translation tells you what words say. LACUNA tells you what words activate. The Nanking treaty translates perfectly. But Chinese pulls shame, English pulls magnanimity."</p>
</div>

<hr>

<h2>Demo Script (2 min)</h2>

<div class="step">
  <div class="step-num">0:00 - 0:15 | THE HOOK</div>
  <p>"Wittgenstein said the limits of my language are the limits of my world. When two languages read the same text, they're reading two different worlds. LACUNA shows you exactly where those worlds diverge."</p>
</div>
<div class="step">
  <div class="step-num">0:15 - 0:25 | WHAT IT DOES</div>
  <p>"Give it a sentence and two languages. It tells you what each language hears differently. Not translation. Activation."</p>
</div>
<div class="step">
  <div class="step-num">0:25 - 0:45 | TERRAIN</div>
  <p>Show terrain in English, switch to German. "43 concepts from the Treaty of Versailles, positioned by embedding proximity, height by centrality. Switch languages -- watch the landscape reshape. Same concepts, different geometry."</p>
</div>
<div class="step">
  <div class="step-num">0:45 - 1:25 | SYKES-PICOT PROBE (center of demo)</div>
  <p>Click the Sykes-Picot probe button. Terrain shifts to Arabic. Amber concepts glow. Pause. Read the results panel. "English hears accountability, mandate, honor. Arabic hears subjugation, humiliation, resentment. Same text. Same model. The gap is the finding."</p>
</div>
<div class="step">
  <div class="step-num">1:25 - 1:40 | THE PATTERN</div>
  <p>"5 texts, 5 language pairs. The pattern holds every time. Imperial languages hear justice. Colonized languages hear shame."</p>
</div>
<div class="step">
  <div class="step-num">1:40 - 1:50 | INTERPRETER</div>
  <p>Click a concept from the results. "Mistral's interpreter agent explains why it diverges -- in real time, grounded in embedding distances."</p>
</div>
<div class="step">
  <div class="step-num">1:50 - 2:00 | CLOSE</div>
  <p>"Before you deploy AI in 10 languages, LACUNA shows you where your content lands differently. Same text. Different world. We built the instrument that reads the gap."</p>
</div>

<hr>

<h2>Tech Stack</h2>

<dl class="vocab">
  <dt>mistral-embed</dt><dd>Live probe embeddings. 1 API call per query, 1024-dim vectors.</dd>
  <dt>Mistral Large</dt><dd>Interpreter + Extractor agents via Agents API.</dd>
  <dt>BGE-M3</dt><dd>Terrain topology. Sentence-level embeddings, 1024-dim. UMAP-projected to 2D.</dd>
  <dt>Next.js 14</dt><dd>App router, API routes, server-side rendering (terrain loads client-only).</dd>
  <dt>Three.js / R3F</dt><dd>3D terrain mesh, postprocessing (Bloom, Vignette, ChromaticAberration).</dd>
  <dt>Python</dt><dd>Offline pipeline: concept extraction, embedding, UMAP projection, weight computation, lacuna detection.</dd>
</dl>

<h2>Vocabulary</h2>

<dl class="vocab">
  <dt>Concept</dt><dd>One of 43 ideas extracted from the Treaty of Versailles. Each has a native-language definition per language.</dd>
  <dt>Cluster</dt><dd>Color group (6 total). Curated by theme. Color only, no effect on probes.</dd>
  <dt>Lacuna</dt><dd>A concept present in one language but absent in another. Shows as a terrain depression.</dd>
  <dt>Divergence</dt><dd>|cos(query, lang_a_vec) - cos(query, lang_b_vec)|. The gap between how two languages activate a concept.</dd>
  <dt>Direction</dt><dd>Which language a concept leans toward. Blue = lang_a, red = lang_b, grey = neutral.</dd>
  <dt>Probe</dt><dd>Text input. 1 mistral-embed call, 86 cosine comparisons, ranked by divergence.</dd>
  <dt>Topology</dt><dd>The 2D layout of concepts. Changes per language because different embedding vectors = different UMAP positions.</dd>
</dl>

<div class="footer">
  L'ECART -- Mistral Worldwide Hackathon -- NYC -- Feb 28-Mar 1, 2026
</div>

</body>
</html>
